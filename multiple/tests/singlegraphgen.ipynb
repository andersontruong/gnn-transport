{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numba.cuda.cudadrv.devices._DeviceList at 0x28bcf56cca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import cupy\n",
    "import random\n",
    "import os\n",
    "import grape\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import pickle\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# os.environ['NUMBA_DEBUG'] = '1'\n",
    "# os.environ['NUMBA_ENABLE_CUDASIM'] = '1'\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from graphcuda import generate_random_adjacency_matrix, floyd_warshall_gpu, faq_align\n",
    "\n",
    "cuda.gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def damage_graph(A: np.array, max_deleted_edges=10):\n",
    "    assert A.shape[0] == A.shape[1]\n",
    "\n",
    "    result = cupy.copy(A)\n",
    "\n",
    "    # Upper triangle # entries: N(Nâˆ’1)/2\n",
    "    edges = cupy.nonzero(cupy.triu(A, 1))\n",
    "    edges = list(map(cupy.asnumpy, edges))\n",
    "    random_indices = np.random.choice(edges[0].shape[0], random.randint(0, max_deleted_edges), replace=False)\n",
    "\n",
    "    for i in random_indices:\n",
    "        x = edges[0][i]\n",
    "        y = edges[1][i]\n",
    "        \n",
    "        temp = cupy.copy(result)\n",
    "        temp[y, x] = 0\n",
    "        temp[x, y] = 0\n",
    "        G = nx.from_numpy_array(temp)\n",
    "        if nx.is_connected(G):\n",
    "            result[y, x] = 1000000000\n",
    "            result[x, y] = 1000000000\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_embedding(G: np.array, walk_len=100, num_walks=10, dimension_size=128, p=1, q=2):\n",
    "    folder_path = os.path.join(os.getcwd(), 'tmp')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    temp_file_path = os.path.join(folder_path, 'tmp.tsv')\n",
    "    with open(temp_file_path, 'w') as f:\n",
    "        # Write edgelist\n",
    "        for i, row in enumerate(G[:-1]):\n",
    "            for j, col in enumerate(row[i+1:]):\n",
    "                if col > 0:\n",
    "                    f.write(f'{i}\\t{j + i + 1}\\t{col}\\n')\n",
    "    \n",
    "    # GRAPE Model\n",
    "    grape_model = grape.Graph.from_csv(\n",
    "        # Edges related parameters\n",
    "\n",
    "        ## The path to the edges list tsv\n",
    "        edge_path=temp_file_path,\n",
    "        ## Set the tab as the separator between values\n",
    "        edge_list_separator=\"\\t\",\n",
    "        ## The first rows should NOT be used as the columns names\n",
    "        edge_list_header=False,\n",
    "        ## The source nodes are in the first nodes\n",
    "        sources_column_number=0,\n",
    "        ## The destination nodes are in the second column\n",
    "        destinations_column_number=1,\n",
    "        ## Both source and destinations columns use numeric node_ids instead of node names\n",
    "        edge_list_numeric_node_ids=True,\n",
    "        ## The weights are in the third column\n",
    "        weights_column_number=2,\n",
    "\n",
    "        # Graph related parameters\n",
    "        ## The graph is undirected\n",
    "        directed=False,\n",
    "        ## The name of the graph is HomoSapiens\n",
    "        name=\"Temp Grape Graph\",\n",
    "        ## Display a progress bar, (this might be in the terminal and not in the notebook)\n",
    "        verbose=True,\n",
    "    )\n",
    "    walks = grape_model.complete_walks(\n",
    "        walk_length=walk_len,\n",
    "        iterations=num_walks,\n",
    "        return_weight=p, # p\n",
    "        explore_weight=q # q\n",
    "    )\n",
    "\n",
    "    grape_word2vec = Word2Vec(\n",
    "        walks.tolist(),\n",
    "        vector_size=dimension_size,\n",
    "        window=5,\n",
    "        min_count=0,\n",
    "        sg=1,\n",
    "        workers=16,\n",
    "        epochs=10,\n",
    "        seed=123\n",
    "    )\n",
    "    \n",
    "    return grape_word2vec.wv.vectors\n",
    "\n",
    "def distance_sum(G: np.ndarray):\n",
    "    fw = floyd_warshall_gpu(G)\n",
    "    return cupy.sum(fw)\n",
    "\n",
    "def get_edgelist(A: np.ndarray) -> list[tuple]:\n",
    "    return [(i, j) for (i, j), val in np.ndenumerate(np.triu(A, k=1)) if val > 0]\n",
    "\n",
    "def get_weightlist(A: np.ndarray) -> list[tuple]:\n",
    "    return [val for _, val in np.ndenumerate(np.triu(A, k=1)) if val > 0]\n",
    "\n",
    "def get_edgelist_tensor(A: np.ndarray) -> torch.Tensor:\n",
    "    return torch.tensor(get_edgelist(A)).t().contiguous()\n",
    "\n",
    "def get_weightlist_tensor(A: np.ndarray) -> torch.Tensor:\n",
    "    return torch.tensor(get_weightlist(A))\n",
    "\n",
    "def sparse_mx_to_torch_sparse_tensor(sparse_mx) -> torch.FloatTensor:\n",
    "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
    "    \n",
    "    sparse_mx = sparse_mx.tocoo().astype(float)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
    "    # FOR UNWEIGHTED, data only contains ones!!!!\n",
    "    values = torch.from_numpy(sparse_mx.data)\n",
    "    shape = torch.Size(sparse_mx.shape)\n",
    "    return torch.sparse.FloatTensor(indices, values, shape)\n",
    "    \n",
    "class SGNNSample:\n",
    "    def __init__(self, base, max_deleted_edges: int = 10, walk_len: int = 100, num_walks: int = 10, dimension_size: int = 256, p: int = 1, q: int = 2, seed: int = 42, max_iter_align: int = 30):\n",
    "\n",
    "        self.seed = seed\n",
    "        self.max_deleted_edges = max_deleted_edges\n",
    "\n",
    "        self.G_base = base\n",
    "\n",
    "        self.G_modified = damage_graph(self.G_base, max_deleted_edges=max_deleted_edges)\n",
    "        # self.G_modified = faq_align(self.G_base, self.G_modified, seed=seed, max_iter=max_iter_align)\n",
    "\n",
    "        self.edgelist_base     = get_edgelist_tensor(self.G_base)\n",
    "        self.edgelist_modified = get_edgelist_tensor(self.G_modified)\n",
    "\n",
    "        self.weightlist_base     = get_weightlist_tensor(self.G_base)\n",
    "        self.weightlist_modified = get_weightlist_tensor(self.G_modified)\n",
    "\n",
    "        self.embedding_base = get_embedding(self.G_base, walk_len=walk_len, num_walks=num_walks, dimension_size=dimension_size, p=p, q=q)\n",
    "        self.embedding_base = csr_matrix(self.embedding_base)\n",
    "        self.embedding_base = sparse_mx_to_torch_sparse_tensor(self.embedding_base)\n",
    "        \n",
    "        self.embedding_modified = get_embedding(self.G_modified, walk_len=walk_len, num_walks=num_walks, dimension_size=dimension_size, p=p, q=q)\n",
    "        self.embedding_modified = csr_matrix(self.embedding_modified)\n",
    "        self.embedding_modified = sparse_mx_to_torch_sparse_tensor(self.embedding_modified)\n",
    "\n",
    "        self.centrality_base = distance_sum(self.G_base)\n",
    "        self.centrality_modified = distance_sum(self.G_modified)\n",
    "\n",
    "        self.centrality_ratio = 1 - (self.centrality_modified - self.centrality_base) / self.centrality_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes   = 500\n",
    "prob_edge = 1.2/(100-1)\n",
    "N = 1000\n",
    "\n",
    "base = generate_random_adjacency_matrix(n_nodes, prob_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "pairs = [SGNNSample(base) for _ in tqdm(range(N), position=0, desc='N', leave=False, ncols=100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "training_file = 'graphs_500_single_normalized.pkl'\n",
    "with open(training_file, 'rb') as f:\n",
    "    pairs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "def normalize_centrality(pairs):\n",
    "    centrality_min = min(pairs, key=lambda pair: pair.centrality_ratio).centrality_ratio\n",
    "\n",
    "    for pair in pairs:\n",
    "        pair.centrality_ratio_normalized = (pair.centrality_ratio - centrality_min) / (1 - centrality_min)\n",
    "        # print(pair.centrality_ratio_normalized)\n",
    "\n",
    "normalize_centrality(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'graphs_{n_nodes}_single_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(pairs, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
